{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "import sqlite3\n",
    "import datetime\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "global_start = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data into Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('final.sqlite')\n",
    "data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews \"\"\", conn)\n",
    "conn.close()\n",
    "\n",
    "print('Shape of our data : {}'.format(data.shape))\n",
    "data.head(3)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly Sample 30k  points from 364k points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = data.sample(n=30000, random_state=42).reset_index(drop=True)\n",
    "del data # To free up the RAM\n",
    "print('shape of our sampled data : {}'.format(sample_data.shape))\n",
    "print('\\n Distribution of class label : \\n{}'.format(sample_data['Score'].value_counts(normalize=True)))\n",
    "sample_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Based Splitting\n",
    "We arrange the sampled data in ascending order of **Time** column and split the data without shuffling such that:\n",
    "* Train_data = First 70%\n",
    "* Test_data = Last 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Time\n",
    "sample_data = sample_data.sort_values('Time').reset_index(drop=True)\n",
    "\n",
    "X_text = sample_data.iloc[:,10] # Selecting the 'CleanedText' column\n",
    "y = sample_data.iloc[:,6] # Selecting the 'Score' column\n",
    "del sample_data # Free up the RAM\n",
    "\n",
    "# Split the data\n",
    "X_text_train, X_text_test, y_train, y_test = train_test_split(X_text, y, test_size=0.30, shuffle=False)\n",
    "\n",
    "# Sanity check\n",
    "print('Shape of X_text_train : {}'.format(X_text_train.shape))\n",
    "print('Shape of y_train : {}'.format(y_train.shape))\n",
    "print()\n",
    "print('Shape of X_text_test : {}'.format(X_text_test.shape))\n",
    "print('Shape of y_test : {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "We will create KNN model based on the following features:\n",
    "* **Bag of words**\n",
    "* **tf-idf**\n",
    "* **avg_word2vec**\n",
    "* **tf-idf weighted word2vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_cv(X_train,y_train):\n",
    "    \n",
    "    # values of K to iterate over.\n",
    "    neighbors = list(np.arange(1,30,2))\n",
    "    \n",
    "    # To store acc and error corresponding to each k.\n",
    "    cv_acc = {}\n",
    "    cv_error = {}\n",
    "    \n",
    "    # perform 10-fold cross validation\n",
    "    for k in neighbors:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "        cv_acc[k] = scores.mean()\n",
    "        cv_error[k] = 1-scores.mean()\n",
    "       \n",
    "    # Find the optimal k value\n",
    "    optimal_k = min(cv_error, key=cv_error.get)\n",
    "    \n",
    "    return (cv_acc, cv_error, optimal_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ************** Creating Bag Of Words ***************************\n",
    "count_vec = CountVectorizer()\n",
    "X_train = count_vec.fit_transform(X_text_train)\n",
    "print('Type of X_train : {}'.format(type(X_train)))\n",
    "print('Shape of X_train : {}'.format(X_train.get_shape()))\n",
    "print('Number of unique words : {}'.format(X_train.get_shape()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********************** 10 - fold Cross Validation **********************\n",
    "start = datetime.datetime.now()\n",
    "cv_acc, cv_error, optimal_k = knn_cv(X_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(cv_acc.keys(), cv_acc.values())\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('KNN BOW ACCURACY')\n",
    "plt.show()\n",
    "\n",
    "print('The optimum value of K based on cross-validation is : {}'.format(optimal_k))\n",
    "print('Time taken : {}'.format(datetime.datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********************* Accuracy on Test Data ***********************\n",
    "X_test = count_vec.transform(X_text_test)\n",
    "knn = KNeighborsClassifier(n_neighbors=optimal_k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "pred = knn.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "\n",
    "print('Accuracy on Testing data is : {}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************** Creating TFIDF Vectors ***************************\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "X_train = tfidf_vec.fit_transform(X_text_train)\n",
    "print('Type of X_train : {}'.format(type(X_train)))\n",
    "print('Shape of X_train : {}'.format(X_train.get_shape()))\n",
    "print('Number of unique words : {}'.format(X_train.get_shape()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************* 10-fold Cross Validation************************\n",
    "start = datetime.datetime.now()\n",
    "cv_acc, cv_error, optimal_k = knn_cv(X_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(cv_acc.keys(), cv_acc.values())\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('KNN TF-IDF ACCURACY')\n",
    "plt.show()\n",
    "\n",
    "print('The optimum value of K based on cross-validation is : {}'.format(optimal_k))\n",
    "print('Time taken : {}'.format(datetime.datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************** Accuracy on Test Data ********************\n",
    "X_test = tfidf_vec.transform(X_text_test)\n",
    "knn = KNeighborsClassifier(n_neighbors=optimal_k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "pred = knn.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "\n",
    "print('Accuracy on Testing data is : {}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************* Tokenize training reviews ********************\n",
    "review_list = []\n",
    "for review in X_text_train:\n",
    "    review_list.append(review.split())\n",
    "\n",
    "print(X_text_train.iloc[0])\n",
    "print()\n",
    "print(review_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************** Word2Vec **********************\n",
    "\n",
    "# min_count = 5 considers only words that occured atleast 5 times\n",
    "w2v_model=Word2Vec(review_list,min_count=5,size=50, workers=4)\n",
    "\n",
    "w2v_words = list(w2v_model.wv.vocab)\n",
    "print(\"number of words that occured minimum 5 times \",len(w2v_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************** Converting training reviews to vectors ********************\n",
    "\n",
    "X_train = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for review in review_list: # for each review/sentence\n",
    "    review_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    cnt_words = 0; # num of words with a valid vector in the sentence/review\n",
    "    for word in review: # for each word in a review/sentence\n",
    "        if word in w2v_words:\n",
    "            vec = w2v_model.wv[word]\n",
    "            review_vec += vec\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        review_vec /= cnt_words\n",
    "    X_train.append(review_vec)\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "print('Type of X_train : {}'.format(type(X_train)))\n",
    "print('Shape of X_train : {}'.format(X_train.shape))\n",
    "print('Number of dimensions : {}'.format(X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************* 10-fold Cross Validation************************\n",
    "start = datetime.datetime.now()\n",
    "cv_acc, cv_error, optimal_k = knn_cv(X_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(cv_acc.keys(), cv_acc.values())\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('KNN AVG-W2V ACCURACY')\n",
    "plt.show()\n",
    "\n",
    "print('The optimum value of K based on cross-validation is : {}'.format(optimal_k))\n",
    "print('Time taken : {}'.format(datetime.datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********** Tokenize test reviews *****************\n",
    "review_list = []\n",
    "for review in X_text_test:\n",
    "    review_list.append(review.split())\n",
    "\n",
    "print(X_text_test.iloc[0])\n",
    "print()\n",
    "print(review_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **************** Converting test reviews to vectors ****************\n",
    "X_test = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for review in review_list: # for each review/sentence\n",
    "    review_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    cnt_words = 0; # num of words with a valid vector in the sentence/review\n",
    "    for word in review: # for each word in a review/sentence\n",
    "        if word in w2v_words:\n",
    "            vec = w2v_model.wv[word]\n",
    "            review_vec += vec\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        review_vec /= cnt_words\n",
    "    X_test.append(review_vec)\n",
    "\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "print('Type of X_test : {}'.format(type(X_test)))\n",
    "print('Shape of X_test : {}'.format(X_test.shape))\n",
    "print('Number of dimensions : {}'.format(X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************** Accuracy on Test Data **************************\n",
    "knn = KNeighborsClassifier(n_neighbors=optimal_k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "pred = knn.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "\n",
    "print('Accuracy on Testing data is : {}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Weighted Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************* Tokenize training reviews ********************\n",
    "review_list = []\n",
    "for review in X_text_train:\n",
    "    review_list.append(review.split())\n",
    "\n",
    "print(X_text_train.iloc[0])\n",
    "print()\n",
    "print(review_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********************** Word2Vec**************************\n",
    "# min_count = 5 considers only words that occured atleast 5 times\n",
    "w2v_model=Word2Vec(review_list,min_count=5,size=50, workers=4)\n",
    "\n",
    "w2v_words = list(w2v_model.wv.vocab)\n",
    "print(\"number of words that occured minimum 5 times \",len(w2v_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********************** TF-IDF **************************\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "tfidf_vec.fit(X_text_train)\n",
    "idf_dict = dict(zip(tfidf_vec.get_feature_names(), tfidf_vec.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************** Converting Training Reviews to vectors *************\n",
    "\n",
    "X_train = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for review in review_list: # for each review/sentence\n",
    "    review_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    weight_sum = 0; # num of words with a valid vector in the sentence/review\n",
    "    for word in review: # for each word in a review/sentence\n",
    "        if word in w2v_words:\n",
    "            vec = w2v_model.wv[word]\n",
    "            tf_idf = idf_dict[word]*(review.count(word)/len(review))\n",
    "            review_vec += (vec * tf_idf)\n",
    "            weight_sum += tf_idf\n",
    "    if weight_sum != 0:\n",
    "        review_vec /= weight_sum\n",
    "    X_train.append(review_vec)\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "print('Type of X_train : {}'.format(type(X_train)))\n",
    "print('Shape of X_train : {}'.format(X_train.shape))\n",
    "print('Number of dimensions : {}'.format(X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************* 10-fold Cross Validation************************\n",
    "start = datetime.datetime.now()\n",
    "cv_acc, cv_error, optimal_k = knn_cv(X_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(cv_acc.keys(), cv_acc.values())\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('KNN TFIDF-W2V ACCURACY')\n",
    "plt.show()\n",
    "\n",
    "print('The optimum value of K based on cross-validation is : {}'.format(optimal_k))\n",
    "print('Time taken : {}'.format(datetime.datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********** Tokenize test reviews *****************\n",
    "review_list = []\n",
    "for review in X_text_test:\n",
    "    review_list.append(review.split())\n",
    "\n",
    "print(X_text_test.iloc[0])\n",
    "print()\n",
    "print(review_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************** Converting Test reviews to vectors *************\n",
    "X_test = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for review in review_list: # for each review/sentence\n",
    "    review_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    weight_sum = 0; # num of words with a valid vector in the sentence/review\n",
    "    for word in review: # for each word in a review/sentence\n",
    "        if word in w2v_words:\n",
    "            vec = w2v_model.wv[word]\n",
    "            tf_idf = idf_dict[word]*(review.count(word)/len(review))\n",
    "            review_vec += (vec * tf_idf)\n",
    "            weight_sum += tf_idf\n",
    "    if weight_sum != 0:\n",
    "        review_vec /= weight_sum\n",
    "    X_test.append(review_vec)\n",
    "\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "print('Type of X_test : {}'.format(type(X_test)))\n",
    "print('Shape of X_test : {}'.format(X_test.shape))\n",
    "print('Number of dimensions : {}'.format(X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************** Accuracy on Test Data **************************\n",
    "knn = KNeighborsClassifier(n_neighbors=optimal_k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "pred = knn.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "\n",
    "print('Accuracy on Testing data is : {}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "We got the best Test Accuracy with the following:\n",
    "* **Model** : Average Word2Vec\n",
    "* **Optimum K** : 15\n",
    "* **Accuracy** : 0.847"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Time Taken to run the entire notebook : {}'.format(datetime.datetime.now()-global_start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
